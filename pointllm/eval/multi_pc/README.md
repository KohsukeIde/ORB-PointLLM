# ORB-PointLLM Multi-Cloud Evaluation Suite

Complete evaluation suite for testing ORB-PointLLM's multi-cloud functionality and comparing with Original PointLLM.

## ğŸ¯ Quick Start - Comparison with Original PointLLM

**To run comparison between Original PointLLM and ORB-PointLLM:**

```bash
cd comparison
./run_comparison.bash
```

This is the **main script** you need for comparing implementations!

## ğŸ“ Directory Structure

```
multi_pc/
â”œâ”€â”€ ğŸ”§ comparison/                     # MAIN: Original vs ORB-PointLLM comparison
â”‚   â”œâ”€â”€ run_comparison.bash            # ğŸ¯ PRIMARY SCRIPT - Run this!
â”‚   â”œâ”€â”€ README.md                      # Detailed comparison guide
â”‚   â””â”€â”€ comparison_results/            # Generated comparison results
â”œâ”€â”€ ğŸ“ core/                           # Core evaluation engine
â”‚   â”œâ”€â”€ eval_multi_cloud.py            # Main evaluation script
â”‚   â””â”€â”€ README.md                      # Core functionality docs
â”œâ”€â”€ ğŸ“ basic_tests/                    # Basic functionality tests
â”‚   â”œâ”€â”€ quick_test.bash                # 5-minute basic test
â”‚   â”œâ”€â”€ gpu_test.bash                  # GPU functionality test
â”‚   â””â”€â”€ multi_test.bash                # Multi-task test
â”œâ”€â”€ ğŸ“ original_prompts/               # Original PointLLM prompt testing
â”‚   â”œâ”€â”€ test_original_prompts.bash     # Comprehensive original prompt test
â”‚   â””â”€â”€ quick_original_test.bash       # Quick original prompt test
â”œâ”€â”€ ğŸ“ utils/                          # Debug utilities
â”‚   â””â”€â”€ debug_dataloader.bash          # Dataloader debugging
â”œâ”€â”€ ğŸ“ docs/                           # Documentation
â””â”€â”€ ğŸ“ initial_test/                   # Initial development tests
```

## ğŸš€ Usage Scenarios

### 1. ğŸ¯ Compare Original PointLLM vs ORB-PointLLM (RECOMMENDED)

```bash
cd comparison
./run_comparison.bash          # Default: 20 samples
./run_comparison.bash 5 5      # Quick test: 5 samples  
./run_comparison.bash 50 50    # Comprehensive: 50 samples
```

**What it does:**
- Runs both Original PointLLM and ORB-PointLLM with identical conditions
- Uses sequential sampling for fair comparison
- Analyzes object_id consistency and model outputs
- Provides comprehensive comparison report

### 2. ğŸ§ª Test Basic Functionality

```bash
cd basic_tests
./quick_test.bash              # 5-minute basic functionality test
./gpu_test.bash                # Test GPU compatibility
./multi_test.bash              # Test multiple tasks
```

### 3. ğŸ“ Test Original PointLLM Prompts

```bash
cd original_prompts
./quick_original_test.bash     # Quick test with original prompts
./test_original_prompts.bash   # Comprehensive original prompt test
```

### 4. ğŸ”§ Debug Issues

```bash
cd utils
./debug_dataloader.bash        # Debug data loading issues
```

## ğŸ“Š Key Features

### Sequential Sampling for Comparison
- **Purpose**: Ensures object_id consistency between implementations
- **Usage**: `--use_sequential_sampling` flag
- **Result**: Identical object sequences for fair comparison

### Original Prompt Support
- **Prompts**: "What is this?", "This is an object of"
- **Usage**: `--use_original_prompts` flag
- **Purpose**: Test compatibility with Original PointLLM training data

### Multi-Cloud Tasks
- **object_identification**: Single cloud object recognition
- **shape_matching**: Compare multiple objects
- **part_assembly**: Analyze object relationships
- **geometric_reasoning**: Spatial relationship analysis

## ğŸ‰ Success Indicators

### Comparison Success
```
ğŸ¯ Object Matching Rate: 20/20 (100.0%)
ğŸ† EXCELLENT: Results are highly comparable!
âœ… Implementation consistency verified
```

### Basic Test Success
```
âœ… Single cloud evaluation: PASSED
âœ… Multi-cloud evaluation: PASSED  
âœ… Model loading: PASSED
âœ… Data processing: PASSED
```

## ğŸ› ï¸ Troubleshooting

### CUDA Environment Issues
```bash
# Check GPU availability
nvidia-smi

# Set specific GPU
export CUDA_VISIBLE_DEVICES=0

# If CUDA unavailable, scripts will use CPU mode
```

### Path Issues
```bash
# Always run from the appropriate directory:
cd /groups/gag51404/ide/ORB-PointLLM/pointllm/eval/multi_pc/[subdirectory]
```

## ğŸ“‹ Dependencies

- **Model**: `RunsenXu/PointLLM_7B_v1.2`
- **Data**: `/groups/gag51404/ide/PointLLM/data/modelnet40_data/modelnet40_test_8192pts_fps.dat`
- **Environment**: PointLLM conda environment with transformers, torch, etc.

## ğŸ¯ Recommended Workflow

1. **Start with basic test**: `basic_tests/quick_test.bash`
2. **Run comparison**: `comparison/run_comparison.bash` 
3. **Test original prompts**: `original_prompts/quick_original_test.bash`
4. **Debug if needed**: `utils/debug_dataloader.bash`

## ğŸ“ˆ Expected Performance

- **Basic test**: ~5 minutes
- **Comparison (20 samples)**: ~10-15 minutes
- **Comprehensive test (50 samples)**: ~30-40 minutes

The evaluation suite ensures ORB-PointLLM maintains full compatibility with Original PointLLM while providing multi-cloud capabilities for advanced point cloud analysis. 